{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Industrial Equipment Sensors \u2013 Data Cleaning Workflow\n", "\n", "This notebook documents the complete cleaning workflow for the **Equipment Sensor Dataset**.\n", "\n", "It assumes you have a raw file named `equipment_sensors_raw.xlsx` in the same folder.\n", "\n", "Main steps:\n", "- Load dataset\n", "- Standardize column names\n", "- Clean string-based fields (status, operator, location, shift)\n", "- Parse mixed timestamp formats\n", "- Convert noisy numeric sensor readings\n", "- Handle missing data\n", "- Remove duplicates\n", "- Treat extreme sensor outliers\n", "- Export cleaned dataset as `equipment_sensors_clean.xlsx`\n"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["import pandas as pd\n", "import numpy as np\n", "\n", "pd.set_option('display.max_columns', None)\n", "pd.set_option('display.width', 160)\n", "print('pandas version:', pd.__version__)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 1. Load raw data"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["raw_path = 'equipment_sensors_raw.xlsx'\n", "df_raw = pd.read_excel(raw_path)\n", "df_raw.head()"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["df_raw.info()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 2. Standardize column names"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["df = df_raw.copy()\n", "df.columns = (\n", "    df.columns.str.strip()\n", "              .str.lower()\n", "              .str.replace(r'\\s+', '_', regex=True)\n", "              .str.replace('[()]', '', regex=True)\n", ")\n", "df.head()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 3. Clean string-based categorical fields"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["# Clean object columns\n", "for col in df.select_dtypes(include='object').columns:\n", "    df[col] = df[col].astype(str).str.strip()\n", "    df[col] = df[col].replace({'': np.nan, 'na': np.nan, 'NA': np.nan, '?': np.nan})\n", "\n", "cat_cols = ['location', 'status', 'operator', 'shift']\n", "for col in cat_cols:\n", "    if col in df.columns:\n", "        df[col] = df[col].str.upper()\n", "\n", "df[cat_cols].head()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 4. Convert timestamps"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["if 'timestamp' in df.columns:\n", "    df['timestamp'] = pd.to_datetime(df['timestamp'], errors='coerce')\n", "df[['timestamp']].head()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 5. Convert noisy numeric sensor readings"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["numeric_cols = ['temperature_c', 'pressure_bar', 'vibration_mms']\n", "\n", "for col in numeric_cols:\n", "    if col in df.columns:\n", "        df[col] = df[col].astype(str).str.replace(r'[^0-9\\.-]', '', regex=True)\n", "        df[col] = pd.to_numeric(df[col], errors='coerce')\n", "\n", "df[numeric_cols].head()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 6. Handle missing values"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["# Drop rows missing critical ID\n", "if 'record_id' in df.columns:\n", "    df = df.dropna(subset=['record_id'])\n", "\n", "# Impute numeric columns\n", "for col in numeric_cols:\n", "    if col in df.columns:\n", "        df[col] = df[col].fillna(df[col].median())\n", "\n", "df.isna().sum()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 7. Remove duplicates"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["before = len(df)\n", "df = df.drop_duplicates()\n", "after = len(df)\n", "print('Duplicates removed:', before - after)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 8. Outlier treatment (temperature, pressure, vibration)"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["def cap_outliers(col):\n", "    q1 = df[col].quantile(0.25)\n", "    q3 = df[col].quantile(0.75)\n", "    iqr = q3 - q1\n", "    upper = q3 + 1.5 * iqr\n", "    return df[col].clip(upper=upper)\n", "\n", "for col in numeric_cols:\n", "    if col in df.columns:\n", "        df[col + '_capped'] = cap_outliers(col)\n", "\n", "df[[c for c in df.columns if 'temperature' in c]].head()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 9. Final checks"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["df.info()"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["df.describe(include='all').transpose().head(20)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 10. Export cleaned dataset"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["clean_path = 'equipment_sensors_clean.xlsx'\n", "df.to_excel(clean_path, index=False)\n", "print('Cleaned file saved to:', clean_path)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["---\n", "### Notes for Upwork / Portfolio\n", "- Demonstrates cleaning industrial sensor logs\n", "- Handles mixed timestamp formats\n", "- Converts noisy sensor readings\n", "- Removes outliers, missing data, duplicates\n", "- Produces ML-ready dataset for anomaly detection and predictive maintenance"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "version": "3.10"}}, "nbformat": 4, "nbformat_minor": 5}